{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKPF61ROdbZm"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download(\"brown\")\n",
        "from nltk.corpus import brown\n",
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer as tfidf\n",
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity \n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = \"/content/drive/MyDrive/assignment3/SimLex-999.txt\"\n",
        "sim_lex_corpus = pd.read_csv(file,sep=\"\\t\")\n",
        "wordlist1 = list()\n",
        "wordlist2 = list()\n",
        "similarity_score = list()\n",
        "for index,row in sim_lex_corpus.iterrows():\n",
        "  wordlist1.append(row[\"word1\"])\n",
        "  wordlist2.append(row[\"word2\"])\n",
        "  similarity_score.append(float(row[\"SimLex999\"]))"
      ],
      "metadata": {
        "id": "KAglC7KTdhxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfIdfVectorizer=tfidf(use_idf=True)"
      ],
      "metadata": {
        "id": "VzAwAlVRecsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Corpus_data = brown.sents(categories=['news'])\n",
        "tfIdf = tfIdfVectorizer.fit_transform(Corpus_data)\n",
        "d = pd.DataFrame(tfIdf.T.todense())\n",
        "cos = cosine_similarity(d)\n",
        "a = tfIdfVectorizer.vocabulary_.keys()\n",
        "vocabulary = list()\n",
        "for i in a:\n",
        "    vocabulary.append(i)"
      ],
      "metadata": {
        "id": "_M6ueBsZdj9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "window_size_list = [1, 2, 5, 10]\n",
        "vector_size_list = [10, 50, 100, 300]\n",
        "iteration_number = 1000\n",
        "sentences_list = [('news', brown.sents(categories=['news'])), ('romance', brown.sents(categories=['romance']))]\n",
        "\n",
        "\n",
        "# for windows_size in windows_size_list:\n",
        "#     for vector_size in vector_size_list:\n",
        "#         for sentences in sentences_list:\n",
        "#             model = Word2Vec(sentences=sentences[1],size=vector_size,window=windows_size,iter=iteration_number,min_count=1,workers=2)\n",
        "#             name = f'word2vec_genre_{sentences[0]}_vector_size_{vector_size}_window_size_{windows_size}_iteration_number_{iteration_number}.model'\n",
        "#             model.save(name)\n",
        "#             print(f\"{name} trained successfully.\")\n",
        "\n",
        "model = Word2Vec(sentences=brown.sents(categories=['news']),size=10,window=1,iter=1000,min_count=1,workers=2)\n"
      ],
      "metadata": {
        "id": "rAS4ShaMdkhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in wordlist1:\n",
        "  try:\n",
        "    print(f'{word}:{model.wv.most_similar(str(word), topn=10)}')\n",
        "  except:\n",
        "    continue"
      ],
      "metadata": {
        "id": "V5GOZyj-d2jk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}